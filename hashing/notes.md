{
# Hash map v/s Hash set 
# | Feature        | HashMap              | HashSet                    |
# | -------------- | -------------------- | -------------------------- |
# | **Stores**     | Key â†’ Value pairs    | Only values (no keys)      |
# | **Duplicates** | Keys must be unique  | Values must be unique      |
# | **Use Case**   | Lookup by key        | Check existence of a value |
# | **Example**    | `{â€œnameâ€: â€œAmbadyâ€}` | `{â€œappleâ€, â€œbananaâ€}`      |

# Use a HashMap when:
# You need to associate one value with another (e.g., username â†’ password, product â†’ price).

# Use a HashSet when:
# You just care about unique elements and fast lookups (e.g., seen items, blocked users, duplicates remover).
}

{
# What is Rehashing?

# ğŸ”´ If too many items get crammed into too few buckets â†’ collisions increase, and performance drops.
# âœ… To fix this, rehashing is done:
# Increase the number of buckets (usually double).
# Recalculate (rehash) each key using the new size.
# Re-insert them into the new table.


# ğŸ“Š Example
# Say you have a small hash table of size = 4, and you keep inserting items.

# After a threshold (say 75% full = 3 items), rehashing triggers:

# # Imagine this internal process
# table = [None] * 4  # Original size

# # Adding keys:
# "apple" â†’ index 0  
# "banana" â†’ index 1  
# "mango" â†’ index 1 (collision!)

# Rehashing triggered:
# â¡ Double table size â†’ size = 8
# â¡ Recalculate index for each key using new size
# â¡ Insert each key into new table with updated index

# âš ï¸ Important: Load Factor

# ğŸ’¡ What is Load Factor?
# It tells you how full your hash table is.
# Load Factor = number of items / table size

# âš ï¸ Why Load Factor Matters?

# Because as the load factor increases:
# Collisions increase âš”ï¸
# Performance drops âŒ
# Hash table can no longer guarantee O(1) search/insert/delete
# So to avoid this, we keep the load factor below a threshold (usually 0.75 or 75%)
# If the load factor crosses a threshold (e.g., 0.75), rehashing occurs.
# This ensures O(1) lookup time on average is maintained.

# ğŸ” What Happens When Load Factor Exceeds Threshold?
# â†’ Rehashing is triggered:
# Create a new table with more buckets (usually double)
# Recompute the hash for each key
# Move all keys to new table (this is costly but rare)

# ğŸ”¥ Real Talk
# In Python, rehashing is automatic in dict and set. You donâ€™t need to do it manually.
# But for interviews, custom hash tables, and performance tuning â†’ you NEED to understand this.
}

{
# | Sorting Algorithm  | Time (Avg) | Space    | Stable?   | Use Cases                                |
# | ------------------ | ---------- | -------- | -------   | ---------------------------------------- |
# | **Bubble Sort**    | O(nÂ²)      | O(1)     | âœ… Yes   | Teaching beginners, small datasets       |
# | **Insertion Sort** | O(nÂ²)      | O(1)     | âœ… Yes   | Small arrays, nearly sorted data         |
# | **Selection Sort** | O(nÂ²)      | O(1)     | âŒ No    | When memory writes are costly            |
# | **Merge Sort**     | O(n log n) | O(n)     | âœ… Yes   | Large stable sorts, linked lists         |
# | **Quick Sort**     | O(n log n) | O(log n) | âŒ No    | Fastest general-purpose sort for arrays  |
# | **Heap Sort**      | O(n log n) | O(1)     | âŒ No    | Constant space sorting, priority queues  |
# | **TimSort**        | O(n log n) | O(n)     | âœ… Yes   | Real-world hybrid sort (used in Python)  |
# | **Radix Sort**     | O(nk)      | O(n+k)   | âœ… Yes   | Sorting integers, strings in linear time |
}


{
# Double Hashing (A Type of Collision Resolution)

# Double Hashing is a technique to resolve collisions in open addressing
# Double Hashing - A collision-resolution method using a 2nd hash function
# Python dict/set handles rehashing and resizing internally, but doesnâ€™t use double hashing
# No, double hashing is NOT the automatic resizing (doubling) of the table. Itâ€™s a technique used to handle collisions using a second hash function.
# So, Second Hash Function is used only:
# ğŸ”„ When collision happens.
# During insertion or search (and deletion, if implemented).
# To compute step size and probe for the next available slot.
# If no collision â†’ no second hash needed.
}

{
# Always mention â€œPython uses TimSort which is stableâ€ when asked about sorting â€” it's a pro-level insight that impresses interviewers.
# | Algorithm                    | Stable?           |
# | ---------------------------- | ----------------- |
# | **Bubble Sort**              | âœ… Yes             |
# | **Insertion Sort**           | âœ… Yes             |
# | **Merge Sort**               | âœ… Yes             |
# | **TimSort** (used by Python) | âœ… Yes             |
# | **Quick Sort**               | âŒ No (by default) |
# | **Heap Sort**                | âŒ No              |
# | **Selection Sort**           | âŒ No              |
}

{
# what is Stable sorting?
# What is Timsort?

# | What         | Timsort                                                           |
# | ------------ | ----------------------------------------------------------------- |
# | Combines     | Merge Sort + Insertion Sort                                       |
# | Python Uses  | Yes, for `.sort()` and `sorted()`                                 |
# | Fastest For  | Real-world data, partially sorted, small inputs                   |
# | Stable?      | âœ… Yes (preserves equal-element order)                             |
# | Use It When? | Always â€” it's default in Python, no need to manually implement it |

# âš™ï¸ How Timsort Works â€” Step-by-Step

# ğŸ”¹ Step 1: Divide the data into runs

# A run is a small chunk of data that is already sorted (ascending or descending).
# If not sorted, itâ€™s sorted using insertion sort.
# Usually run size = 32 or 64 elements (platform-dependent)

# ğŸ”¹ Step 2: Sort small runs using Insertion Sort

# Why? Because insertion sort is super fast for small arrays.
# Python sorts these small chunks first.

# ğŸ”¹ Step 3: Merge runs using Merge Sort

# Sorted runs are then merged together.
# Merging is done stably, preserving order of equal items.
# But TimSort doesnâ€™t just blindly merge everything â€” it uses clever rules to merge efficiently (called "galloping mode").
}

{
# ğŸ” Core Idea Behind Hash Table:

# You take a key (like "Ambady").
# Run it through a hash function â†’ gives a number (called index).
# Use that number to store the value in an array (bucket).

# So itâ€™s like:
# hash("Ambady") % size â†’ index â†’ go to that index â†’ store/fetch value
}

{
# What are the operations that can be done in Stack and Queue?

# ğŸ”¹ Stack:
# push, pop, peek, is_empty, size
# ğŸ”¹ Queue:
# enqueue, dequeue, front, is_empty, size
}

{
# Explain how hash functions work ?

# A hash function is a function that takes a key (like a string, number, etc.)
# and converts it into an integer index in a fixed range (e.g., 0 to table size - 1).

# index = hash_function(key) % table_size
# That index decides where the value goes in the underlying array (called a bucket).
# Built-in Python hash() Function is there, 
# print(hash("Ambady"))  # â†’ Some large integer
}

{
# What Is a Collision in Hashing?
# A collision occurs when two different keys produce the same hash index in a hash table.
# "abc" â†’ 97+98+99 = 294 â†’ 294 % 10 = 4
# "cab" â†’ 99+97+98 = 294 â†’ 294 % 10 = 4
# ğŸ”¥ Collision! Both keys map to index 4

# ğŸš§ Why Collisions Are Bad

# If collisions arenâ€™t handled:
# New value overwrites existing value Or it gets lost completely Or the program crashes
# âŒ That breaks the hash tableâ€™s guarantee of O(1) lookups
}


{
# ğŸ›¡ How Do We Handle Collisions?

# âœ… 1. Chaining (Separate Chaining)
# Each bucket holds a list of key-value pairs
# If two keys hash to the same index, store both in a list at that index
# table[4] = [("abc", val1), ("cab", val2)]
# âœ… 2. Open Addressing : If a slot is full, find the next empty one

# âœ… TL;DR
# | Term      | Meaning                                               |
# | --------- | ----------------------------------------------------- |
# | Collision | Two different keys â†’ same index in a hash table       |
# | Causes    | Limited buckets, many keys, imperfect hash functions  |
# | Fix It By | Chaining or Open Addressing (probing, double hashing) |
}

{
# Queue Operations: enqueue(), dequeue(), peek(), is_empty(), size(), display()
# Types of Queues: Simple Queue, Circular Queue, Deque, Priority Queue, Double-Ended Priority Queue
}

{
# ğŸ’¥ What is a Monotonic Stack?
# A Monotonic Stack is a stack that keeps its elements in either increasing or decreasing order.

# ğŸ“˜ Two Types:
# Type	Maintains
# Monotonic Increasing Stack	Smallest at bottom, largest at top
# Monotonic Decreasing Stack	Largest at bottom, smallest at top

# ğŸ’¥ What is a Monotonic Queue?
# A Monotonic Queue is a double-ended queue (deque) where elements are kept in sorted order (non-increasing or non-decreasing).

# | Concept             | Used For                     | Structure    | Real Use              |
# | ------------------- | ---------------------------- | ------------ | --------------------- |
# | **Monotonic Stack** | Next Greater/Smaller Element | Stack (LIFO) | Histogram, stock span |
# | **Monotonic Queue** | Max/Min in Sliding Window    | Deque (FIFO) | Sliding window max    |
}

{
# ğŸ§  peek vs pop â€“ Whatâ€™s the Core Difference?
# Operation	What it Does	Removes the Element?	Time Complexity
# peek()	Returns the element at the top/front	âŒ No	âœ… O(1)
# pop()	Returns and removes the element at the top/front
# âš”ï¸ Peek is non-destructive. Pop is destructive.
}

{
# ğŸ’¡ What is Linear Probing?
# Linear Probing is a collision resolution technique in open addressing where,if a slot is full, we simply check the next one (linearly) until we find an empty spot.
}

{
# ğŸ’¡ What is a Circular Queue?
# A Circular Queue is a linear data structure that connects the end of the queue back to the front, forming a circle.
# This allows efficient use of space and avoids shifting elements like in a regular array-based queue.
}



Questions to practice 

Sort a string using stack
Number of occurrence word in a string using hash table
valid anagram using hash map
valid parenthesis
implement merge sort
valid anagram using hashtable
two sum in O n time
3rd largest element from unsorted array
